{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12bea12324c032d8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import hashlib # for grading\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "from numpy.testing import assert_allclose\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# SKLearn related imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da97614b7076e26a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Q1. Cars Price\n",
    "\n",
    "For the first question, you will be making use of regex to extract some information from the dataset `cars.txt` in the data folder. In this dataset, you'll find a list of cars that have been sold, as well as their brand, model and selling price.\n",
    "\n",
    "Start by loading the data into a list of sentences. Each sentence is separated by a new line in the `.txt` file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2e5273236adf54e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "path = \"data/cars.txt\"\n",
    "cars = []\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    cars = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2b06a7ac18252021",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cars[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32879d17b087c102",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the first item, for example, `FORD` is the brand name, `Focus` is the model, and `19757` is the price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-999bbbabdecd84cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q1.a)\n",
    "\n",
    "First, we want to see which `TOYOTA` cars have been sold. Return the full strings corresponding to cars that belong to this brand in a list assigned to a variable `ans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d7292940dd0f0b2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ans = [ ... ]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d5ce92d78b9b815",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(ans) == 111\n",
    "assert hashlib.sha256(' '.join(sorted(ans)).encode()).hexdigest() == \\\n",
    "    'e187e5b04c2a7cb863905c1abe8d5a791782dd80a1e3ae08430978e0bc5623e1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9eeeb76b6d1ab67c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1.b)\n",
    "\n",
    "Next, find all cars whose model is a set of numbers instead of characters. For example, `'BMW -- 535 -- 23521'`.\n",
    "\n",
    "Return the full strings corresponding to these cars  in the variable `ans_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dccb1f349ce02a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ans_models = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-98c96bad0127da20",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(ans_models) == 73\n",
    "assert hashlib.sha256(' '.join(sorted(ans_models)).encode()).hexdigest() == \\\n",
    "    '5f08454f40915f9cd36de32ed145322f618d01051db706c1f6f81c5e8877c8e7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fcd2e99fd51f7864",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1.c)\n",
    "\n",
    "Finally, get the car brands and models whose selling price was bellow 1000.\n",
    "\n",
    "Save the results in the list `ans_price`. Each element on this list should be in the format `BRAND -- MODEL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b8146ce9f0ba50df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ans_price = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b746057a51e92a5d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(ans_price) == 77\n",
    "assert hashlib.sha256(' '.join(sorted(ans_price)).encode()).hexdigest() == \\\n",
    "    '7b0ee55a70f3aab0435a140162df3f89aff25ba1b3b1c7b9c2b7d43e1660044d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7271784ba90d3ce9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Q2. Job postings (preprocessing)\n",
    "\n",
    "The challenge of this exercise notebook is to classify job posting as 'Fake' or 'Real' using the posts' text. To do that, we first need to preprocess the data.\n",
    "\n",
    "Let's start by briefly analyzing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c69e26f590ef0c78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/job_postings.csv', index_col=0)\n",
    "\n",
    "X = df['description']\n",
    "y = df['fraudulent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-254c128c0c743d4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's look at an example of a job description and it's corresponding label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad805151accfbdc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[10]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cf38bca6e1a69176",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[10]['fraudulent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dbdc0548dd699460",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's check the data size and distribution of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-622a8322d87daf24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_data_stats(X, y):\n",
    "    print(f\"Size of dataset: {len(X)}\")\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"Distribution of classes: {dict(zip(unique, counts))}\")\n",
    "\n",
    "get_data_stats(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-808b90ccd21d360d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The classes are evenly distributed. We'll use a dev and test sets to be able to identify overfitting and check the performance on unseen data.\n",
    "\n",
    "**Note**: So far you've used the `train`/`val`/`test` nomenclature for naming variables related to training, validation and test sets, respectively. `dev` is short for \"development\" and is just another typical identifier for the validation set, and we'll use it throughout this notebook instead of `val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a524119b37972d48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train dev test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp)\n",
    "print(f\"Train size: {len(X_train)}\\nDev size: {len(X_dev)}\\nTest size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e93f9088c1da685e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Since the goal is to turn the strings in X into useful features, now we will be performing common preprocessing operations on the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-addc0c904c359402",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.a)\n",
    "\n",
    "First, tokenize the data. Implement the function to receive a list of strings and an NLTK-style tokenizer, and return the list but with tokenized strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8b7930a61806e32",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_tokenizer(data, tokenizer):\n",
    "    \"\"\"\n",
    "    Returns a list of sentences that have been tokenized with the provided `tokenizer`\n",
    "    \n",
    "    E.g. for an input [\"This is a test!\", \"No, it can't be\"],\n",
    "         it should return [\"This is a test !\", \"No , it can ' t be\"]\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings containing the text to tokenize\n",
    "    tokenizer - nltk tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f829c5a222c54690",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "data_tok = apply_tokenizer(X_train, tokenizer)\n",
    "\n",
    "assert len(data_tok) == 1530\n",
    "assert isinstance (data_tok, list)\n",
    "assert all(isinstance(sentence, str) for sentence in data_tok)\n",
    "\n",
    "assert len([w for s in data_tok for w in s.split(\" \")]) == 665508\n",
    "assert hashlib.sha256(data_tok[100].encode()).hexdigest() == \\\n",
    "    '80a21ceb29cbdfda6f15e4c2def79894ca64f4231a8a9a27dbe9805d7c1a8c55'\n",
    "assert hashlib.sha256(data_tok[875].encode()).hexdigest() == \\\n",
    "    '39c7f9fa57ecc57060c6db546fbdb4a2de201e41c6a6a466286c977039e94fdd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b76d100b971a777f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.b)\n",
    "\n",
    "The second step you will implement is lowercasing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee47fb5a45fbd622",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_lowercase(data):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, with all the tokens lowercased.\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings to be lowercased\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7979e12840663ea2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data_tok_lc = apply_lowercase(data_tok)\n",
    "\n",
    "assert len(data_tok_lc) == 1530\n",
    "assert isinstance (data_tok_lc, list)\n",
    "assert all(isinstance(sentence, str) for sentence in data_tok_lc)\n",
    "assert not any(c.isupper() for s in data_tok_lc for w in s.split(\" \") for c in w)\n",
    "\n",
    "assert len([w for s in data_tok_lc for w in s.split(\" \")]) == 665508\n",
    "assert hashlib.sha256(data_tok_lc[56].encode()).hexdigest() == \\\n",
    "    '1f5cf4311e169eb2f53d8b06f556362d06358a3259f302fa56bdf06dcd06136a'\n",
    "assert hashlib.sha256(data_tok_lc[785].encode()).hexdigest() == \\\n",
    "    '4cb3727db93c102e455124d672acc00c629bb65f71a73a1a48f3ceb31619f9ff'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8044c14c20583cf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.c)\n",
    "\n",
    "Now implement a function that filters the stopwords. We will use NLTK's built-in English stopword list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3f0dea2c5108c93a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42ecb29c8fe117f1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_filter_stopwords(data, stopword_list):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, where the strings do not contain any of\n",
    "        the stopwords in the given list.\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings to filter stopwords from\n",
    "    stopword_list - list of stopwords to filter out\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter the stopwords from the text\n",
    "    # data_no_stopwords = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return data_no_stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f70da0255ea6e291",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data_tok_lc_nosw = apply_filter_stopwords(data_tok_lc, stopword_list)\n",
    "\n",
    "assert len(data_tok_lc_nosw) == 1530\n",
    "assert isinstance (data_tok_lc_nosw, list)\n",
    "assert all(isinstance(sentence, str) for sentence in data_tok_lc_nosw)\n",
    "assert not any(any(w in stopword_list for w in s.split(\" \")) for s in data_tok_lc_nosw)\n",
    "\n",
    "assert len([w for s in data_tok_lc_nosw for w in s.split(\" \")]) == 472520\n",
    "assert hashlib.sha256(data_tok_lc_nosw[325].encode()).hexdigest() == \\\n",
    "    '4b114a2e69b98612a8d5e6b47fc41411d3414f3a9f21740cc75eb9451787cf01'\n",
    "assert hashlib.sha256(data_tok_lc_nosw[4].encode()).hexdigest() == \\\n",
    "    'ed242f390891d3f8dd5ef8b27f8f5e7031d8b3338c2790a7989c8bb0928fed9c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8d0cb317596faa2f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.d)\n",
    "\n",
    "After filtering stopwords, we want to remove punctuation from the text as well. Consider only the tokens in `string.punctuation` to be single punctuation characters. Make sure to remove all punctuation and not only tokens that are single punctuation characters. \n",
    "\n",
    "_Hint: check the note on punctuation in Part 2 of the learning notebooks_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a0cd3cf5cc97a8f2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_filter_punct(data):\n",
    "    \"\"\"\n",
    "    Returns a list of tokenized sentences with no punctuation.\n",
    "    \n",
    "    Args:\n",
    "    data - list of tokenized sentences from which to remove punctuation\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-31c9a6a65413aef8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_tok_lc_nosw_nopunct = apply_filter_punct(data_tok_lc_nosw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-925e418acc339a2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Normalize whitespaces\n",
    "\n",
    "Run the following function on `data_tok_lc_nosw_nopunct` before checking your answers, in case extra whitespaces cause the asserts to fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67539c50de422305",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_whitespace(data):\n",
    "    return [re.sub(r\"^\\s+|\\s+$|(?<=\\s)\\s*\", \"\", text) for text in data]\n",
    "\n",
    "data_tok_lc_nosw_nopunct_norm = normalize_whitespace(data_tok_lc_nosw_nopunct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-650a677a3a01d1bf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(data_tok_lc_nosw_nopunct_norm) == 1530\n",
    "assert len([w for s in data_tok_lc_nosw_nopunct_norm for w in s.split(\" \")]) == 379730\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm[74].encode()).hexdigest() == \\\n",
    "    '377fd8129ab959bb9b184093e6afe2a7812a579484bd63fdc28245736c37e442'\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm[965].encode()).hexdigest() == \\\n",
    "    '8ea25acf67aa0a5a36d5733f72cc7c3f345336c8044f390bee3b63ad31f8ac15'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-38d66dd89731e114",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.e)\n",
    "\n",
    "The last preprocessing step you are going to implement is stemming. Implement the function to receive an NLTK-style stemmer and return the text as a string with the stemmer applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a831ba989f3e50e6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_stemmer(data, stemmer):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, with stemmed data.\n",
    "    \n",
    "    Args:\n",
    "    data - list with text to stem\n",
    "    stemmer - instance of stemmer to use\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "data_tok_lc_nosw_nopunct_norm_stem = apply_stemmer(data_tok_lc_nosw_nopunct_norm, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3596a6510ebbda3d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "data_tok_lc_nosw_nopunct_norm_stem = apply_stemmer(data_tok_lc_nosw_nopunct_norm, stemmer)\n",
    "\n",
    "assert len(data_tok_lc_nosw_nopunct_norm_stem) == 1530\n",
    "assert len([w for s in data_tok_lc_nosw_nopunct_norm_stem for w in s.split(\" \")]) == 379730\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm_stem[854].encode()).hexdigest() == \\\n",
    "    '59b37c27fe05b0e3d20df96df763b82dca7ec28fe2bd0164c10d257db852a63d'\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm_stem[21].encode()).hexdigest() == \\\n",
    "    'c116aa8dbd9c3f4785aae448aad52c2e9b2d9fd5b0f3b28e451affd8f3e3e8f1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bfe5aed6ebdbb26",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.f)\n",
    "\n",
    "Finally, join everything in a function, that applies the steps in the following order:\n",
    "* Tokenization\n",
    "* Lowercasing\n",
    "* Filtering stopwords\n",
    "* Filtering punctuation\n",
    "* Normalizing whitespace\n",
    "* Stemming\n",
    "\n",
    "Make use of the functions you designed above when filling the transformer below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ea5b2305431c20dd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Custom transformer to implement sentence cleaning\n",
    "class TextCleanerTransformer(TransformerMixin):\n",
    "    def __init__(self, tokenizer, lower=True, remove_punct=True, stopwords=[], stemmer=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "        self.lower = lower\n",
    "        self.remove_punct = remove_punct\n",
    "        self.stopwords = stopwords\n",
    "    \n",
    "    def clean_sentences(self, data):\n",
    "                \n",
    "        # Tokenize sentence so it each sentence contains spaced words or tokens\n",
    "        # sentences_preprocessed = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # Lowercase\n",
    "        if self.lower:\n",
    "            # sentences_preprocessed = ...\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        if self.stopwords:\n",
    "            # sentences_preprocessed = ...\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "        # Remove punctuation\n",
    "        if self.remove_punct:\n",
    "            # sentences_preprocessed = ...\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        # Normalize whitespace\n",
    "        # sentences_preprocessed = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "        # Stem words\n",
    "        if self.stemmer:\n",
    "            # sentences_preprocessed = ...\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        return sentences_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a4c1aa16cea2ffb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "text_cleaner = TextCleanerTransformer(\n",
    "    WordPunctTokenizer(),\n",
    "    lower=True, \n",
    "    remove_punct=True, \n",
    "    stopwords=stopwords.words('english'),\n",
    "    stemmer=SnowballStemmer(\"english\"),\n",
    ")\n",
    "\n",
    "X_train_pre = text_cleaner.clean_sentences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4a87d0c9b1f20f7e",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(X_train_pre) == 1530\n",
    "assert len([w for s in X_train_pre for w in s.split(\" \")]) == 379730\n",
    "assert X_train_pre[1352][:150] == ('traffic manag web mobil mx mex mexico nan companyadcash Â® intern advertis network deliv billion ad unit month reach sever million peopl around globe s')\n",
    "assert X_train_pre[342][:150] == ('physic therapist us ca orovill nan welcom interfac rehabinterfac rehab provid comprehens rehabilit physic occup amp speech therapi amp consult servic ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f48abbdab8acc3d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Q3. Text classification\n",
    "\n",
    "We will now use what we've learned to try to classify the job postings as fake or real. Let's first load the preprocessed data and double-check the balance of the classes.\n",
    "\n",
    "We are loading the preprocessed csv file here. This way you won't be penalized if you were not able to finish the preprocessing part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6cfef332c9bd3d0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    \"\"\"\n",
    "    Loads a csv file and returns two lists, one\n",
    "    containing only the text and one containing the labels\n",
    "    \n",
    "    Args:\n",
    "    file_name: path to input file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_name, index_col = 0)\n",
    "\n",
    "    return list(df['description']), list(df['fraudulent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99de6cc5a4a3ff52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_pre, y_train = load_dataset('data/job_postings_train_preprocessed.csv')\n",
    "X_dev_pre, y_dev = load_dataset('data/job_postings_dev_preprocessed.csv')\n",
    "X_test_pre, y_test = load_dataset('data/job_postings_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfca3c5348fd2262",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "get_data_stats(X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aaf6fbf5dbc51f95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "get_data_stats(X_dev_pre, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e5147de37fa0351",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So, we should be aiming for much better than 45% accuracy, which is what we would get if we naively predicted `1` (fake) for everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a844631e7326ff6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.a)\n",
    "\n",
    "First, we'll look at the top X ngrams in each category to see if anything is interesting. Write a function that returns the most common n-grams and their count for a specific label in our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36567f8f392a4836",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_ngrams_for_category(text, labels, filter_label, top_n=10, ngram_size=1):\n",
    "    \"\"\"\n",
    "    Filters the data to the desired label, constructs a counter of ngrams\n",
    "    Returns the top n ngrams\n",
    "    \n",
    "    Args:\n",
    "    text: list of text strings to get ngrams from\n",
    "    labels: categories corresponding to text\n",
    "    filter_label: the label to filter the data on before getting ngrams\n",
    "    top_n: top n ngrams to return\n",
    "    ngram_size: the \"n\" in ngram (e.g. if ngram_size=2, return only bigrams)\n",
    "    \"\"\"\n",
    "    # First, filter text to desired category\n",
    "    # text_filtered = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Create list of ngrams\n",
    "    # ngram_list = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Count occurances of each ngram\n",
    "    # hint: use collections.Counter\n",
    "    # ngram_counter = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # return top_n most common ngrams\n",
    "    # hint: use a method of collections.Counter\n",
    "    # return ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cca0190cfba4ad83",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_10_unigrams_real = top_ngrams_for_category(X_train_pre, y_train, 0, top_n=10, ngram_size=1)\n",
    "assert top_10_unigrams_real == [(('nan',), 3199),\n",
    "                                    (('work',), 2689),\n",
    "                                    (('experi',), 1966),\n",
    "                                    (('manag',), 1854),\n",
    "                                    (('team',), 1830),\n",
    "                                    (('servic',), 1773),\n",
    "                                    (('develop',), 1706),\n",
    "                                    (('custom',), 1624),\n",
    "                                    (('compani',), 1430),\n",
    "                                    (('time',), 1428)]\n",
    "top_6_unigrams_fake = top_ngrams_for_category(X_train_pre, y_train, 1, top_n=6, ngram_size=1)\n",
    "assert top_6_unigrams_fake == [(('nan',), 3318),\n",
    "                                  (('work',), 1828),\n",
    "                                  (('manag',), 1303),\n",
    "                                  (('experi',), 1287),\n",
    "                                  (('time',), 1221),\n",
    "                                  (('servic',), 1187)]\n",
    "top_5_bigrams_real = top_ngrams_for_category(X_train_pre, y_train, 0, top_n=5, ngram_size=2)\n",
    "assert top_5_bigrams_real == [(('nan', 'nan'), 1349),\n",
    "                                  (('full', 'time'), 745),\n",
    "                                  (('custom', 'servic'), 398),\n",
    "                                  (('bachelor', 'degre'), 308),\n",
    "                                  (('year', 'experi'), 211)]\n",
    "top_10_trigrams_fake = top_ngrams_for_category(X_train_pre, y_train, 1, top_n=10, ngram_size=3)\n",
    "assert top_10_trigrams_fake == [(('nan', 'nan', 'nan'), 851),\n",
    "                                 (('nan', 'full', 'time'), 165),\n",
    "                                 (('time', 'nan', 'nan'), 138),\n",
    "                                 (('high', 'school', 'equival'), 134),\n",
    "                                 (('full', 'time', 'nan'), 131),\n",
    "                                 (('oil', 'gas', 'industri'), 123),\n",
    "                                 (('time', 'entri', 'level'), 116),\n",
    "                                 (('full', 'time', 'entri'), 104),\n",
    "                                 (('level', 'high', 'school'), 92),\n",
    "                                 (('mid', 'senior', 'level'), 89)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05f81b8870270b19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Looking at the top ngrams for each category, it doesn't seem like a BoW model will be very interesting, but let's try anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1a096ee6776427b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.b)\n",
    "To begin, let's streamline our pipeline in a nice function. We'll use sklearn's `CountVectorizer` instead of the function we wrote. We'll also use the `LogisticRegression` classifier to make predictions on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af90809e6c74e780",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_validate(X_train, X_dev, y_train, y_dev, ngram_range=(1,1), max_features=None):\n",
    "    \"\"\"\n",
    "    Train a model using sklearn's Pipeline and return it along with the predictions and the\n",
    "    current accuracy in the validation set. Print the classification report as well.\n",
    "    Assume the documents are already preprocessed\n",
    "    \n",
    "    Args:\n",
    "    X_train - preprocessed articles in training data\n",
    "    X_dev - preprocessed articles in dev data\n",
    "    y_train - labels of training data\n",
    "    y_dev - labels of dev data\n",
    "    ngram_range - ngram range to use in CountVectorizer (tuple)\n",
    "    max_features - max number of features to use in CountVectorizer (int)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build the pipeline containing the countvectorizer and the multinomial NB classifier\n",
    "    # text_clf = Pipeline(...)\n",
    "    \n",
    "    # Train the classifier\n",
    "    # (...)\n",
    "\n",
    "    # y_dev_pred = (...)\n",
    "    \n",
    "    # acc = (...)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # print the classification report\n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "\n",
    "    # return text_clf, y_dev_pred, acc\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-97ba1cceed5a53f9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "clf, y_dev_pred, acc = train_and_validate(X_train_pre, X_dev_pre, y_train, y_dev)\n",
    "\n",
    "# check same as before\n",
    "assert_allclose(clf['clf'].intercept_, np.array([0.73381536]), rtol=1e-3)\n",
    "assert ' '.join(str(i) for i in y_dev_pred[:20]) == \"0 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 0 0\"\n",
    "assert hashlib.sha256(' '.join(str(i) for i in y_dev_pred).encode()).hexdigest() == \\\n",
    "    \"7ed40ca221aaaf17d3647bd204045ae4799558b377e8ec37fbc464ee9731113a\"\n",
    "assert_allclose(acc, 0.90, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d7678b7610a7200f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# we should also look at some misclassified examples\n",
    "for text, pred, true in zip(X_dev_pre[:70], y_dev_pred[:70], y_dev[:70]):\n",
    "    if pred != true:\n",
    "        print(f\"Sentence: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c7cbbc0c3275557",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So just with the simplest BoW model we already get an accuracy of 0.9o! But let's see if we can do even better... In the misclassified examples, the last one even contains a strange url but classified as 'fake'. That's suspicious..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4fd66e62c165a4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.c)\n",
    "Run the pipeline for different ngram ranges and/or with different values for max_features. Try to achieve an accuracy higher or equal to 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e75ac8652cc7e741",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# clf,y_dev_pred, acc = train_and_validate(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-722d1b4ff466bdd7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(acc >= 0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76675b1b36125145",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now evaluate your model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dcb6e703b4c8ed64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_test_vec = clf['vect'].transform(X_test_pre)\n",
    "y_test_pred = clf['clf'].predict(X_test_vec)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711b6cc0145d445c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Great! We were able to improve the model a little on the dev set and the performance on the test set is pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28921443e50007c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4. TF-IDF\n",
    "\n",
    "Similarly to how we found the top ngrams before we started working with BoW, we will now find the most important unigrams, inverse weighted by document frequency.\n",
    "\n",
    "**Note**: Throughout this exercise, we'll use this term - **most important** - to refer to the unigrams of the highest weight, in particular within each class, since these will be transferred into vectors used for training. It is not 100% true these features will necessarily be \"the most important\", but in general they will be relevant, especially if your dataset is correctly processed, so we'll use this expression as a proxy.\n",
    "\n",
    "#### Q4.a)\n",
    "\n",
    "First, implement TF-IDF on a dataframe representing a Bag of Words model of the data. Here is a reminder of the TF-IDF formula:\n",
    "\n",
    "$$ tfidf _{t, d} =(log{(1 + tf_{t,d})})*(log{(1 + \\frac{N}{df_{t}})})  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5b15b82e46b905ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# We'll start you off with the BoW representation, in pandas dataframe format\n",
    "vec = CountVectorizer()\n",
    "BoW_train = vec.fit_transform(X_train_pre)\n",
    "BoW_train_df = pd.DataFrame(BoW_train.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b915bab713aba13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tfidf(BoW_df):\n",
    "    \"\"\"\n",
    "    Returns pandas dataframe of a tfidf representation from a BoW representation dataframe.\n",
    "\n",
    "    Args:\n",
    "    BoW_df - dataframe with document word counts (Bag of Words)\n",
    "    \"\"\"\n",
    "    # remember that the BoW representation is raw counts, it is not normalized by the length of each text\n",
    "    # first transform the df into term frequencies, where the counts are normalized\n",
    "    # also double check the formula above for additional transformations applied to the tf expression\n",
    "    # use np.log(x) for natural base log\n",
    "    # tf = (...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # now we need a function that computes the idf side of the expression\n",
    "    # it operates over a column (a word in the vocab), where the column contains each doc's count of that word\n",
    "    # def _idf(column):\n",
    "    #   return (...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # now weight the term frequencies by the idfs\n",
    "    # tf_idf = (...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-86090d8867691e1a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tfidf_df = tfidf(BoW_train_df)\n",
    "assert math.isclose(tfidf_df.iloc[1525, 1], 0.0175562, abs_tol=0.0001)\n",
    "assert math.isclose(tfidf_df.iloc[0, 2505], 0.003557, abs_tol=0.0001)\n",
    "assert math.isclose(tfidf_df.iloc[344, 3405], 0.0194850, abs_tol=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5794b50d39898cfc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.b)\n",
    "\n",
    "Now that we have our TF-IDF representation, we can proceed with getting the most important words per category. \n",
    "\n",
    "Let's write a small helper function first to get the vocabulary in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8143a657d8b668d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get the vocab from CountVectorizer, which is of the format {\"word\": idx, ...}\n",
    "vocab_word_2_idx = vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4cf0289cdb72e49a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# write a function to convert this vocab to the format {idx: \"word\", ...}\n",
    "\n",
    "def reverse_vocab(vocab_word_to_index):\n",
    "    \"\"\"\n",
    "    Converts a vocabulary dictionary with words as keys and indices as values to a \n",
    "        new dictionary with indices as keys and words as values\n",
    "    \n",
    "    Args:\n",
    "    vocab_word_to_index: vocabulary dict of the format {\"word\": 0, \"hello\": 1, ...}\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2c86ba6062add631",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "vocab_idx_2_word = reverse_vocab(vocab_word_2_idx)\n",
    "assert len(vocab_idx_2_word) == 18647\n",
    "assert vocab_idx_2_word[1231] == \"amount\"\n",
    "assert vocab_idx_2_word[1639] == \"assimil\"\n",
    "assert vocab_idx_2_word[9876] == \"memor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9d199071250b72d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.c)\n",
    "\n",
    "Finally, write a function to return the list of N most important words in each category according to TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00f14b79ff68d32e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_tfidf_words_for_category(tfidf_df, labels, filter_label, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns the top n most important words for the given label, with the given vocabulary\n",
    "    and corresponding tfidf representation of some text data\n",
    "    \n",
    "    Args:\n",
    "    tfidf_df: a dataframe of the tfidf representation of some text (columns=words, rows=documents)\n",
    "    labels: categories corresponding to documents in tfidf_df\n",
    "    filter_label: the label to filter the data on before getting top n words\n",
    "    top_n: top n words to return\n",
    "    \"\"\"\n",
    "    # First, filter tfidf to desired category\n",
    "    # tfidf_filt = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Get the top n words of the current label, according to tfidf\n",
    "    # There are several ways to do this, but here are some hints\n",
    "    # 1) Sum the filtered df to get the total value per word\n",
    "    # 2) Sort\n",
    "    # 3) Replace indices with words and return the top_n\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b51198b450763c2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_15_fake = top_tfidf_words_for_category(tfidf_df, y_train, 1, top_n=15)\n",
    "assert top_15_fake == ['nan',\n",
    "                         'work',\n",
    "                         'time',\n",
    "                         'entri',\n",
    "                         'servic',\n",
    "                         'custom',\n",
    "                         'home',\n",
    "                         'posit',\n",
    "                         'experi',\n",
    "                         'skill',\n",
    "                         'amp',\n",
    "                         'manag',\n",
    "                         'administr',\n",
    "                         'requir',\n",
    "                         'start']\n",
    "top_20_real = top_tfidf_words_for_category(tfidf_df, y_train, 0, top_n=20)\n",
    "assert top_20_real == ['nan',\n",
    "                       'work',\n",
    "                       'develop',\n",
    "                       'experi',\n",
    "                       'manag',\n",
    "                       'sale',\n",
    "                       'custom',\n",
    "                       'team',\n",
    "                       'servic',\n",
    "                       'product',\n",
    "                       'job',\n",
    "                       'market',\n",
    "                       'client',\n",
    "                       'design',\n",
    "                       'busi',\n",
    "                       'compani',\n",
    "                       'time',\n",
    "                       'technolog',\n",
    "                       'nbsp',\n",
    "                       'web']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2672054e4024a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.d)\n",
    "\n",
    "Now, we will put everything together. Rewrite the train_and_validate function from Q3.b but using sklearn's `TfIdfTransformer`. Also, add kwargs for CountVectorizer's `max_df` and `min_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-02453bb681cd33b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_validate_with_tfidf(X_train, X_dev, y_train, y_dev, ngram_range=(1,1),\n",
    "                                  max_features=None, max_df=1.0, min_df=1):\n",
    "    \"\"\"\n",
    "    Train a model using sklearn's Pipeline and return it along with the predictions and the\n",
    "    current accuracy in the validation set. Print the classification report as well.\n",
    "    Assume the documents are already preprocessed\n",
    "    \n",
    "    Args:\n",
    "    X_train - preprocessed articles in training data\n",
    "    X_dev - preprocessed articles in dev data\n",
    "    y_train - labels of training data\n",
    "    y_dev - labels of dev data\n",
    "    ngram_range - ngram range to use in CountVectorizer (tuple)\n",
    "    max_features - max number of features to use in CountVectorizer (int)\n",
    "    max_df = max_df for CountVectorizer (int or float)\n",
    "    min_df = min_df for CountVectorizer (int or float)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build a pipeline containing the countvectorizer, tfidftransformer and the multinomial NB classifier\n",
    "    # text_clf = Pipeline(...)\n",
    "    \n",
    "    # Train the classifier\n",
    "    # (...)\n",
    "\n",
    "    # y_dev_pred = (...)\n",
    "    # print the classification report\n",
    "    # acc = (...)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "\n",
    "    # return text_clf, y_dev_pred, acc\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ee1c189fe642928a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "clf, y_dev_pred, acc = train_and_validate_with_tfidf(X_train_pre, X_dev_pre, y_train, y_dev)\n",
    "\n",
    "assert hashlib.sha256(\" \".join([str(x) for x in list(y_dev_pred)]).encode()).hexdigest() == \\\n",
    "    \"a63704cd531a94f5299f67f20b1e781e41f2f890825dee89fee6a4b536c05024\"\n",
    "assert_allclose(acc, 0.91, rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-87d3359e8827355d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# As before, we should also look at some misclassified examples\n",
    "for text, pred, true in zip(X_dev_pre[:70], y_dev_pred[:70], y_dev[:70]):\n",
    "    if pred != true:\n",
    "        print(f\"Sentence: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26ada9070ceb8872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Unfortunately, we're still not able to correctly classify those sentences. Let's keep going and see if we can do even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab54cc6297c36ee2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q4.e)\n",
    "\n",
    "Use the `train_and_validate_with_tfidf` function you created before to train with different hyperparameters and get an accuracy score above 92% on the validation dataset. (This threshold is the same as what we got for plain CountVectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-07b6f3694941ac8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# clf, _, acc = train_and_validate_with_tfidf(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-07b6f3694941ac81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(acc > 0.92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-123f82e6058cdcdc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now evaluate your model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a5352a2d0b2f2903",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_test_vec = clf['tfidf'].transform(clf['vect'].transform(X_test_pre))\n",
    "y_test_pred = clf['clf'].predict(X_test_vec)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c4aa5fa0188b8ce3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Great results! We were able to slightly improve the performance on the test set compared with using BoW with n-grams ranging from 1 to 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
